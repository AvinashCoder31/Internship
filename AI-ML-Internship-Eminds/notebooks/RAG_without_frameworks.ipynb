{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a20eb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in d:\\rag basics\\venv\\lib\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: sentence-transformers in d:\\rag basics\\venv\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: python-dotenv in d:\\rag basics\\venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: requests in d:\\rag basics\\venv\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in d:\\rag basics\\venv\\lib\\site-packages (from faiss-cpu) (2.3.2)\n",
      "Requirement already satisfied: packaging in d:\\rag basics\\venv\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\rag basics\\venv\\lib\\site-packages (from sentence-transformers) (4.54.0)\n",
      "Requirement already satisfied: tqdm in d:\\rag basics\\venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\rag basics\\venv\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\rag basics\\venv\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in d:\\rag basics\\venv\\lib\\site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\rag basics\\venv\\lib\\site-packages (from sentence-transformers) (0.34.3)\n",
      "Requirement already satisfied: Pillow in d:\\rag basics\\venv\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\rag basics\\venv\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in d:\\rag basics\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\rag basics\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\rag basics\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\rag basics\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\rag basics\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\rag basics\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\rag basics\\venv\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\rag basics\\venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\rag basics\\venv\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\rag basics\\venv\\lib\\site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\rag basics\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\rag basics\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\rag basics\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\rag basics\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\rag basics\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\rag basics\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\rag basics\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\rag basics\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\rag basics\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu sentence-transformers python-dotenv requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a1c3127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1889.36s - thread._ident is None in _get_related_thread!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in d:\\rag basics\\venv\\lib\\site-packages (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26ea75d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\rag basics\\venv\\lib\\site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc1186ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Groq key loaded: ‚ùå (Replace your key manually)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF for reading PDFs\n",
    "import numpy as np\n",
    "import requests\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env variables (if you created one)\n",
    "load_dotenv()\n",
    "\n",
    "# Get your Groq API key\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "GROQ_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "# Print to confirm\n",
    "print(\"‚úÖ Groq key loaded:\", \"‚úîÔ∏è\" if GROQ_API_KEY.startswith(\"gsk_\") else \"‚ùå (Replace your key manually)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa58ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted 1277 chunks from the PDF.\n",
      "\n",
      "üìå First chunk:\n",
      " David Kennedy, Jim O‚ÄôGorman, Devon Kearns, and Mati Aharoni\n",
      "Foreword by HD Moore\n",
      "Metasploit\n",
      "The Penetration Tester‚Äôs Guide\n",
      "METASPLOIT\n",
      "METASPLOIT\n",
      "The Penetration \n",
      "Tester‚Äôs Guide\n",
      "by David Kennedy, \n",
      "Jim O‚ÄôGorman, Devon Kearns, \n",
      "and Mati Aharoni\n",
      "San Francisco\n",
      "METASPLOIT. Copyright ¬© 2011 by David Kenned ...\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    return full_text\n",
    "\n",
    "def chunk_text(text, max_chars=500):\n",
    "    return [text[i:i + max_chars] for i in range(0, len(text), max_chars)]\n",
    "\n",
    "# Replace this with your actual PDF file name\n",
    "pdf_path = \"METASPOILT.pdf\"\n",
    "raw_text = extract_text_from_pdf(pdf_path)\n",
    "chunks = chunk_text(raw_text)\n",
    "\n",
    "print(f\"‚úÖ Extracted {len(chunks)} chunks from the PDF.\")\n",
    "print(\"\\nüìå First chunk:\\n\", chunks[0][:300], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13fc4f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG Basics\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings shape: (1277, 384)\n",
      "üìå Example vector (first chunk):\n",
      " [ 0.01040963  0.0466566  -0.0607655   0.04970527  0.01825979] ...\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode the chunks\n",
    "embeddings = embedder.encode(chunks, convert_to_numpy=True)\n",
    "\n",
    "# Show shape of embedding matrix\n",
    "print(\"‚úÖ Embeddings shape:\", embeddings.shape)\n",
    "print(\"üìå Example vector (first chunk):\\n\", embeddings[0][:5], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b404e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS index created and populated.\n",
      "üìå Total vectors indexed: 1277\n"
     ]
    }
   ],
   "source": [
    "# Create a FAISS index\n",
    "dimension = embeddings.shape[1]  # e.g., 768\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "faiss.write_index(index, \"metasploit_index.faiss\")\n",
    "np.save(\"metasploit_chunks.npy\", chunks)\n",
    "\n",
    "print(\"‚úÖ FAISS index created and populated.\")\n",
    "print(\"üìå Total vectors indexed:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0bea56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load local FAISS index and original text chunks\n",
    "index = faiss.read_index(\"metasploit_index.faiss\")\n",
    "chunks = np.load(\"metasploit_chunks.npy\", allow_pickle=True)\n",
    "\n",
    "# Load embedding model (same as used for chunk embeddings)\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8096fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query: str, top_k=20):\n",
    "    # Step 1: Embed the query using the same model\n",
    "    query_embedding = embedder.encode([query], convert_to_numpy=True)\n",
    "\n",
    "    # Step 2: Search in the FAISS index\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    # Step 3: Return the top-k matched text chunks\n",
    "    return [chunks[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f077f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_answer(query: str, context_chunks):\n",
    "    context = \"\\n\".join([f\"- {chunk}\" for chunk in context_chunks])\n",
    "    prompt = f\"\"\"You are a helpful assistant. Use only the given context to answer the question truthfully. Dont make up answers or hallucinate. If the answer is not in the context, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-8b-8192\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 8000\n",
    "    }\n",
    "\n",
    "    response = requests.post(GROQ_API_URL, headers=headers, json=payload)\n",
    "    result = response.json()\n",
    "\n",
    "    if \"choices\" in result:\n",
    "        return result['choices'][0]['message']['content']\n",
    "    else:\n",
    "        raise Exception(f\"Groq error: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c421b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† LLM Answer:\n",
      "Based on the provided context, the \"Joy of Exploitation\" chapter focuses on the art of exploiting vulnerabilities in a target system. The author emphasizes the importance of doing one's homework before launching an exploit, highlighting the need for precision rather than brute force. The chapter covers the basics of exploitation, including identifying potential vulnerabilities, launching an exploit, and compromising a target system.\n",
      "\n",
      "The author also stresses the importance of post-exploitation, which involves identifying critical infrastructure, targeting information or data that the company values most, and demonstrating attacks that would have the greatest business impact. The chapter provides examples of how to use Metasploit, a penetration testing framework, to perform exploitation and post-exploitation tasks.\n",
      "\n",
      "Throughout the chapter, the author provides guidance on how to avoid detection, use antivirus evasion techniques, and leverage vulnerability scanning technology. The chapter concludes by emphasizing the importance of reporting the findings and results of the penetration test, highlighting the business impact of the attacks and providing valuable information and intelligence to the client.\n",
      "\n",
      "Overall, the \"Joy of Exploitation\" chapter provides a comprehensive overview of the exploitation phase of a penetration test, emphasizing the importance of precision, post-exploitation, and reporting.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give a summary about the joy of exploitation, more elaborate.\"\n",
    "top_chunks = retrieve_chunks(query)\n",
    "answer = generate_answer(query, top_chunks)\n",
    "\n",
    "print(\"\\nüß† LLM Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac828d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished RAG pipeline with manual steps. Next, we will automate this using LangChain.\n"
     ]
    }
   ],
   "source": [
    "#So Far we have done the RAG pipeline: Retrieval and Generation\n",
    "# Next we are going to do it with langchain \n",
    "# S --- IGNORE --- \n",
    "print(\"Finished RAG pipeline with manual steps. Next, we will automate this using LangChain.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
